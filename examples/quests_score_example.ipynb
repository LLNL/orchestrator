{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ffc37b-7e10-4cce-9055-6273a098edeb",
   "metadata": {},
   "source": [
    "In this notebook, we show an example of how to use modules in `orchestrator.computer.score` to compute:\n",
    "* QUESTS dataset efficiency\n",
    "* QUESTS dataset diversity\n",
    "* QUESTS delta entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb9ee0-3f59-4a7d-a184-784f0cd0f9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import orchestrator\n",
    "from orchestrator.utils.input_output import safe_read\n",
    "from orchestrator.utils.setup_input import init_and_validate_module_type\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10481267-df7f-4642-975b-99921277c9a0",
   "metadata": {},
   "source": [
    "First, we load our dataset from local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53b22c-e0ce-45d3-94ad-25d82ed5d68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"./query_configs.extxyz\"\n",
    "dataset = safe_read(dataset_path, index=\":\")\n",
    "print(\"Number of configurations in the dataset:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba50ea0-0102-4473-8f04-ecf7c84d8efe",
   "metadata": {},
   "source": [
    "Alternatively, we could retrieve a dataset from the Colabfit storage, assuming you have already uploaded a dataset to the database.\n",
    "You can check the available datasets by calling `storage.list_data()`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab5e90af-1bc6-4eb2-a8e2-3f90d71b9697",
   "metadata": {
    "tags": []
   },
   "source": [
    "storage_input = {\n",
    "    \"storage_type\":\"COLABFIT\",\n",
    "    \"storage_args\":{\n",
    "        \"credential_file\":\"/PATH/TO/colabfit_credentials.json\"\n",
    "    }\n",
    "}\n",
    "storage = init_and_validate_module_type(\n",
    "    module_name=\"storage\",\n",
    "    input_args=storage_input,\n",
    "    # Set the following argument to True because the input dictionary\n",
    "    # only contains argument for one class instance\n",
    "    single_input_dict=True,\n",
    ")\n",
    "\n",
    "dataset_handle = \"DS_abcde1234fgh_0\"  # This is an internal dataset ID, which you can find using storage.list_data() for datasets that have already been saved\n",
    "dataset = storage.get_data(dataset_handle)\n",
    "print(\"Number of configurations in the dataset:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef412e-3dad-4a51-bb7e-717f219554e8",
   "metadata": {},
   "source": [
    "To compute QUESTS efficiency, diversity, and delta entropy scores, each configuration should have QUESTS descriptor computed, and this information should be stored in `.arrays` within the ASE atoms object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516e497-7ee6-45b3-9112-b23d689349a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate QUESTSDescriptor\n",
    "descriptor_input = {\n",
    "    \"descriptor_type\":\"QUESTSDescriptor\",\n",
    "    \"descriptor_args\": {\n",
    "        \"num_nearest_neighbors\": 32,\n",
    "        \"cutoff\": 5.0\n",
    "    }\n",
    "}\n",
    "descriptor = init_and_validate_module_type(\n",
    "    module_name=\"descriptor\",\n",
    "    input_args=descriptor_input,\n",
    "    single_input_dict=True\n",
    ")\n",
    "\n",
    "# Compute the descriptor\n",
    "calc_ids = descriptor.run(\n",
    "    'quests_descriptor_generation', \n",
    "    compute_args={}, # no special args for computing QUESTS descriptors\n",
    "    configs=dataset,\n",
    "    workflow=None, # will use the default (local) workflow\n",
    "    job_details={}, # no special job_details to modify\n",
    "    batch_size=100, # we'll compute all descriptors at once\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc308-0cd9-4c39-b3b3-cad8ce700152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the output and save to new data. Alternatively could overwrite dataset\n",
    "dataset_with_descriptors = descriptor.data_from_calc_ids(calc_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595c1b2-4dca-4a3a-8d09-cbad5c6fea46",
   "metadata": {},
   "source": [
    "Additionally, we generate a dummy redundant dataset by duplicating the original atomic configurations.\n",
    "Comparing the QUESTS scores of the original and redundant datasets illustrates what each score means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52855185-2e7b-466d-b15a-5549db093aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generated by repeating one of the configuration\n",
    "redundant_dataset = dataset_with_descriptors * 5  # Duplicate the original configurations 5 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f9fa7-c89d-48f0-b54d-c546e69670a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# QUESTS dataset efficiency score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8177ec-fb65-4d45-b69f-6f75e812dec5",
   "metadata": {},
   "source": [
    "The QUESTS dataset efficiency score is computed using `orchestrator.computer.score.quests.QUESTSEfficiencyScore` module.\n",
    "The efficiency score measures how oversample the dataset is.\n",
    "The score near 1 means that the dataset has very little redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9209777-4ba1-41f2-83d4-b3ce5d2dc976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate QUESTSEfficiencyScore\n",
    "score_input = {\"score_type\":\"QUESTSEfficiencyScore\", \"score_args\": {}}\n",
    "score = init_and_validate_module_type(\n",
    "    module_name=\"score\",\n",
    "    input_args=score_input,\n",
    "    # Set the following argument to True because the input dictionary\n",
    "    # only contains argument for one class instance\n",
    "    single_input_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858a117-8e8d-4167-a348-87273ea2d70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the QUESTS efficiency score\n",
    "compute_args = {\n",
    "    \"score_quantity\":\"EFFICIENCY\",\n",
    "    \"apply_mask\": False,\n",
    "    \"descriptors_key\": descriptor.OUTPUT_KEY + \"_descriptors\",  # Key for atoms.arrays dictionary for the precomputed QUESTS descriptor\n",
    "    \"bandwidth\": 0.015  # Gaussian kernel bandwith for KDE, default is 0.015\n",
    "}\n",
    "calc_ids = score.run(\n",
    "    'efficiency_calc',\n",
    "    dataset_with_descriptors, \n",
    "    compute_args, \n",
    "    batch_size=1\n",
    ")\n",
    "efficiency_score = score.data_from_calc_ids(calc_ids)[0][score.OUTPUT_KEY+'_score'][0] # nested list, just have one score\n",
    "print(\"Efficiency score:\", efficiency_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d19e8-d3f9-4a57-938a-cc739c487bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the QUESTS efficiency score for the redundant dataset\n",
    "calc_ids = score.run(\n",
    "    'efficiency_calc',\n",
    "    redundant_dataset, \n",
    "    compute_args, \n",
    "    batch_size=1\n",
    ")\n",
    "efficiency_score = score.data_from_calc_ids(calc_ids)[0][score.OUTPUT_KEY+'_score'][0] # nested list, just have one score\n",
    "print(\"Efficiency score:\", efficiency_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817513a-0867-4099-bdb3-84372be20b60",
   "metadata": {
    "tags": []
   },
   "source": [
    "The QUESTS efficiency score of the original dataset is higher than that of the redundant dataset, implying that the later dataset has more redundancy than the original, which intuitively agrees with how the later dataset is constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746f173-e4db-4629-8d3b-38f7e94e02a2",
   "metadata": {},
   "source": [
    "# QUESTS dataset diversity score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15287e-0fd7-4c02-9c14-b077749405e0",
   "metadata": {},
   "source": [
    "The QUESTS dataset diversity score is calculated using `orchestrator.computer.score.quests.QUESTSDiversityScore`.\n",
    "The diversity score gives a measure of the dataset coverage, i.e., dataset with higher diversity score covers larger regions of the configuration space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64c749-b833-4562-abc5-41d3b604b37f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate QUESTSDiversityScore\n",
    "score_input = {\"score_type\":\"QUESTSDiversityScore\", \"score_args\": {}}\n",
    "score = init_and_validate_module_type(\n",
    "    module_name=\"score\",\n",
    "    input_args=score_input,\n",
    "    single_input_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405348-63ec-4592-99e2-59ae699f6167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the QUESTS diversity score\n",
    "# The arguments are the same as the computation for the dataset efficiency score except the score_quantity\n",
    "compute_args = {\n",
    "    \"score_quantity\": \"DIVERSITY\",\n",
    "    \"apply_mask\": False,\n",
    "    \"descriptors_key\": descriptor.OUTPUT_KEY + \"_descriptors\",  # Key for atoms.arrays dictionary for the precomputed QUESTS descriptor\n",
    "    \"bandwidth\": 0.015\n",
    "}\n",
    "calc_ids = score.run(\n",
    "    'diversity_calc',\n",
    "    dataset_with_descriptors, \n",
    "    compute_args, \n",
    "    batch_size=1\n",
    ")\n",
    "diversity_score = score.data_from_calc_ids(calc_ids)[0][score.OUTPUT_KEY+'_score'][0] # nested list, just have one score\n",
    "print(\"Diversity score:\", diversity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7851a-cc52-4187-8a64-69c892d283e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the QUESTS diversity score for the redundant dataset\n",
    "calc_ids = score.run(\n",
    "    'efficiency_calc',\n",
    "    redundant_dataset, \n",
    "    compute_args, \n",
    "    batch_size=1\n",
    ")\n",
    "diversity_score = score.data_from_calc_ids(calc_ids)[0][score.OUTPUT_KEY+'_score'][0] # nested list, just have one score\n",
    "print(\"Diversity score:\", diversity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30eb014-5712-4823-8611-019611b5ce3c",
   "metadata": {},
   "source": [
    "Notice that the two datasets have the same diversity.\n",
    "Although we have more configurations in the redundant dataset, they don't increase the coverage because they are just duplicates of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e6e05-8aa0-4603-95b5-96aed42a6897",
   "metadata": {},
   "source": [
    "# QUESTS delta entropy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcb87d-fc9f-4124-925a-c514cc80c90d",
   "metadata": {},
   "source": [
    "The QUESTS delta entropy ($\\delta \\mathcal{H}$)score is calculated using `orchestrator.computer.score.quests.QUESTSDeltaEntropyScore`.\n",
    "The delta entropy measures the contribution of a data point (atomic environment) to the total entropy of the reference dataset.\n",
    "Rare environments have large $\\delta \\mathcal{H}$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9984c-181b-497a-a567-0329878ad26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate QUESTSDeltaEntropyScore\n",
    "score_input = {\"score_type\":\"QUESTSDeltaEntropyScore\", \"score_args\": {}}\n",
    "score = init_and_validate_module_type(\n",
    "    module_name=\"score\",\n",
    "    input_args=score_input, \n",
    "    single_input_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d928a98-be29-4ab0-9d3b-00e53b0aafbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we'll compute dH for 2/3 of the dataset referenced to the other 1/3\n",
    "reference = dataset_with_descriptors[:3]\n",
    "reference_descriptors = np.concatenate([c.get_array(descriptor.OUTPUT_KEY+'_descriptors') for c in reference])\n",
    "compute_dataset = dataset_with_descriptors[3:]\n",
    "\n",
    "compute_args = {\n",
    "    \"score_quantity\":\"DELTA_ENTROPY\",\n",
    "    \"reference_set\": reference_descriptors,\n",
    "    \"descriptors_key\": descriptor.OUTPUT_KEY + \"_descriptors\",\n",
    "    \"bandwidth\": 0.015,\n",
    "    \"approx\": False,  # Don't use approximation of dH for this example\n",
    "    \"num_nearest_neighbors\": 3,  # Number of nearest neighbor used in the dH calculation - only used if approx = True\n",
    "    \"graph_neighbors\": 10  # Parameter for performing the approximate nearest neighbor search - only used if approx = True\n",
    "}\n",
    "calc_ids = score.run(\n",
    "    'dH_calc',\n",
    "    compute_dataset, \n",
    "    compute_args,\n",
    "    batch_size=6, # compute all at once\n",
    ")\n",
    "configs_with_score = score.data_from_calc_ids(calc_ids)\n",
    "print(\"Sample Diversity score:\", configs_with_score[0].get_array(score.OUTPUT_KEY+\"_score\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b2ff1-da41-48b4-9959-4010ea24bb79",
   "metadata": {},
   "source": [
    "We can use the delta entropy information to mask (include or exclude) some atomic environments in the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d4125-8803-449c-84ce-68a0d487192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from orchestrator.utils.data_standard import SELECTION_MASK_KEY\n",
    "dH_threshold = -3  # Exclude environment with dH value below this threshold\n",
    "for atoms in configs_with_score:\n",
    "    natoms = atoms.get_global_number_of_atoms()\n",
    "    masks_atoms = np.zeros(natoms, dtype=bool) \n",
    "    masks_atoms[atoms.get_array(score.OUTPUT_KEY+\"_score\") > dH_threshold] = 1\n",
    "    # Add the masking array to atoms.arrays\n",
    "    atoms.set_array(SELECTION_MASK_KEY, masks_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6610ca3-8bf6-4ade-b984-f8a2995502eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_atoms = np.sum([len(x) for x in configs_with_score])\n",
    "atoms_after_mask = np.sum(np.concatenate([x.get_array(SELECTION_MASK_KEY) for x in configs_with_score]))\n",
    "print(f'After masking, a dataset with {total_atoms} atoms was reduced in size to {atoms_after_mask} atoms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orchestrator kernel (Aug)",
   "language": "python",
   "name": "aug_orchestrator_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
